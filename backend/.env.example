# LLM Configuration
# LLM provider: 'ollama' for local or 'openai' for cloud
LLM_PROVIDER=ollama

# Ollama LLM
OLLAMA_MODEL=llama3.2:3b
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_TEMPERATURE=0.1

# OpenAI LLm
OPENAI_API_KEY=your_openai_api_key_here
OPENAI_MODEL=gpt-3.5-turbo
OPENAI_TEMPERATURE=0.1

# Restaurant Booking API
BOOKING_API_URL=http://localhost:8547
BOOKING_API_TOKEN=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJ1bmlxdWVfbmFtZSI6ImFwcGVsbGErYXBpQHJlc2RpYXJ5LmNvbSIsIm5iZiI6MTc1NDQzMDgwNSwiZXhwIjoxNzU0NTE3MjA1LCJpYXQiOjE3NTQ0MzA4MDUsImlzcyI6IlNlbGYiLCJhdWQiOiJodHRwczovL2FwaS5yZXNkaWFyeS5jb20ifQ.g3yLsufdk8Fn2094SB3J3XW-KdBc0DY9a2Jiu_56ud8
RESTAURANT_NAME=TheHungryUnicorn

# Server
HOST=0.0.0.0
PORT=8000
RELOAD=True
LOG_LEVEL=INFO

# Session
SESSION_TIMEOUT_MINUTES=30
MAX_CONVERSATION_LENGTH=20

CORS_ORIGINS=["http://localhost:8000", "http://localhost:3000"]
RATE_LIMIT_REQUESTS=100
RATE_LIMIT_PERIOD=3600

